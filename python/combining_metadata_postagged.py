# -*- coding: utf-8 -*-
"""combining_metadata_postagged.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/148PC-6-6qDrh3pocowVB3QSMVg4_uAcs
"""

import pandas as pd
from datetime import datetime
date = datetime.now().strftime('%Y-%m-%d')
import numpy as np

textOutputPath = "C:\\Users\\joaop\\Desktop\\Corpora\\C-Oral-Brasil\\dissertation_codes\\text_output_files\\" #path for final output

# reading the metadata dataframe
# metadataDf = pd.read_csv(textOutputPath+f'allPeopleInfoDf_csv_{date}.csv')
metadataDf = pd.read_csv(textOutputPath+f"allPeopleInfoDf_csv_2023-05-21.csv")

# reading the pos tagged texts
posTagUtterancesDf = pd.read_csv(textOutputPath+f"\\posTagUtteranceWithInfo_csv_{date}.csv")
#posTagUtterancesDf = pd.read_csv(textOutputPath+f"\\posTagUtteranceWithInfo_csv_2023-09-26.csv")

metadataDf.columns #checking columns

# merging the metadata and the transcription
metadataWithText = metadataDf.merge(posTagUtterancesDf, on="person_code", how="left")

# selecting and reordering columns
metadataWithTextSelected = metadataWithText[['file_x', 'acronym_x', 'person_code', 'unique_id_person', 'sex', 'age', 'schooling', 'context', 'utterance',
       'clean_utterance', 'words_with_tags', 'lemmas', 'pos_tagged',
       'total_words', 'total_utterance', 'total_nonstandard_verb_agreement',
       'total_nonstandard_verb_conjugation', 'total_count_negation','total_non_standard_plural',
       'count_apheresis', 'count_mo_intensifier', 'count_rhotacism',
       'count_senhor_senhora', 'count_diminutive','count_foreign_words',
       'count_prepositions', 'count_pronouns',
       'count_interjections', 'combined_person_info']] # 'count_foreign','count_rotacionism',

# renaming columns
metadataWithTextSelected = metadataWithTextSelected.rename(columns={"file_x": "file", "acronym_x": "acronym"})

print(len(metadataWithTextSelected)) #checking
print(len(metadataWithTextSelected[metadataWithTextSelected.combined_person_info.str.contains("Unknown")==True])) #checking

# selecting only people we have information about
knownPeopleDf = metadataWithTextSelected[(metadataWithTextSelected.age != "x") & (metadataWithTextSelected.schooling != "x") & (metadataWithTextSelected.schooling != "the baby")]

knownPeopleDf.columns #checking

# grouping the rows by the unique ID (thus the speaker)
# obs.: this is to deal with the repeated speakers in the corpus
knownPeopleDf_unique = knownPeopleDf.groupby('unique_id_person')[['file', 'acronym', 'person_code', 'sex', 'age',
       'schooling', 'context', 'utterance', 'clean_utterance',
       'words_with_tags', 'lemmas', 'pos_tagged', 'total_words',
       'total_utterance', 'total_nonstandard_verb_agreement',
       'total_nonstandard_verb_conjugation', 'total_count_negation',
       'total_non_standard_plural', 'count_apheresis', 'count_mo_intensifier',
       'count_rhotacism', 'count_senhor_senhora', 'count_diminutive',
       'count_foreign_words', 'count_prepositions', 'count_pronouns',
       'count_interjections', 'combined_person_info']].agg(lambda x: '--'.join(map(str, x))).reset_index()
# knownPeopleDf_unique = knownPeopleDf_unique.astype(str)
print(len(knownPeopleDf_unique)) #checking

knownPeopleDf_unique[45:48]

# in order to sum the numerical variables from the same speaker in different interactions we need to transform the joined strings into a list
# define the delimiter
delimiter = '--'

# define the function to apply to each element of the dataframe
def split_string(value):
    # split the string by the delimiter
    return value.split(delimiter)

# apply the function to each element of the dataframe using applymap()
knownPeopleDf_splitted = knownPeopleDf_unique.applymap(split_string)

# if there is a speaker with "missing_mo" and "present_mo" in the list -> present_mo is prevalent in teh cell
# define the value to search for
value_to_find = 'present_mo'

# define the function to apply to each element of the dataframe
def is_value_present(row, value):
    '''check if the value is present in any of the lists in the row'''
    for item in row:
        if item == value:
            return value
        else:
            return "missing_mo"

# reorganizing things so that the information is taken out of the list
# social information does not need to be repeated or summed, so we use it as the first item of the list
knownPeopleDf_splitted["unique_id_person"] = knownPeopleDf_splitted['unique_id_person'].apply(lambda x: x[0])
print("done: unique_id_person")
knownPeopleDf_splitted["file"] = knownPeopleDf_splitted['file'].apply(lambda x: x[0])
print("done: file")
knownPeopleDf_splitted["acronym"] = knownPeopleDf_splitted['acronym'].apply(lambda x: x[0])
print("done: acronym")
knownPeopleDf_splitted["person_code"] = knownPeopleDf_splitted['person_code'].apply(lambda x: ",".join(x))
print("done: person_code")
knownPeopleDf_splitted["sex"] = knownPeopleDf_splitted['sex'].apply(lambda x: x[0])
print("done: sex")
knownPeopleDf_splitted["age"] = knownPeopleDf_splitted['age'].apply(lambda x: x[0])
print("done: age")
knownPeopleDf_splitted["schooling"] = knownPeopleDf_splitted['schooling'].apply(lambda x: x[0])
print("done: schooling")
knownPeopleDf_splitted["context"] = knownPeopleDf_splitted['context'].apply(lambda x: ",".join(x))
print("done: context")
knownPeopleDf_splitted["combined_person_info"] = knownPeopleDf_splitted['combined_person_info'].apply(lambda x: x[0])
print("done: combined_person_info")
knownPeopleDf_splitted["utterance"] = knownPeopleDf_splitted['utterance'].apply(lambda x: "".join(x))
print("done: utterance")
knownPeopleDf_splitted["clean_utterance"] = knownPeopleDf_splitted['clean_utterance'].apply(lambda x: "".join(x))
print("done: clean_utterance")
knownPeopleDf_splitted["words_with_tags"] = knownPeopleDf_splitted['words_with_tags'].apply(lambda x: "".join(x))
print("done: words_with_tags")
knownPeopleDf_splitted["lemmas"] = knownPeopleDf_splitted['lemmas'].apply(lambda x: "".join(x))
print("done: lemmas")
knownPeopleDf_splitted["pos_tagged"] = knownPeopleDf_splitted['pos_tagged'].apply(lambda x: "".join(x))
print("done: pos_tagged")

import math

def remove_nan_values(lst):
    return [x for x in lst if not math.isnan(float(x))]

# define a function to apply to the column
def sum_list(col):
    '''
    So, the overall purpose of this function is to convert a list of values to floats,
    sum all the values in the list, and return the sum, or if there is only one value in the list,
    return that value as a float. If the input is not a list, the original value is returned.
    '''
    if isinstance(col, list):
        newNum = remove_nan_values(col)
        if len(newNum) > 1:
            newCol = []
            for i in newNum:
                if i == np.nan:
                    i = 0
                    iNew = float(i)
                    newCol.append(iNew)
                else:
                    iNew = float(i)
                    newCol.append(iNew)
            return round(sum(newCol), 2)
        else:
            return round(float(col[0]), 2)
    else:
        return col

knownPeopleDf_splitted["total_words"] = knownPeopleDf_splitted["total_words"].apply(lambda x: sum_list(x))
print("done: total_words")
knownPeopleDf_splitted["total_utterance"] = knownPeopleDf_splitted["total_utterance"].apply(lambda x: sum_list(x))
print("done: total_utterance")
knownPeopleDf_splitted["total_nonstandard_verb_agreement"] = knownPeopleDf_splitted["total_nonstandard_verb_agreement"].apply(lambda x: sum_list(x))
print("done: total_nonstandard_verb_agreement")
knownPeopleDf_splitted["total_nonstandard_verb_conjugation"] = knownPeopleDf_splitted["total_nonstandard_verb_conjugation"].apply(lambda x: sum_list(x))
print("done: total_nonstandard_verb_conjugation")
knownPeopleDf_splitted["total_count_negation"] = knownPeopleDf_splitted["total_count_negation"].apply(lambda x: sum_list(x))
print("done: total_count_negation")
knownPeopleDf_splitted["total_non_standard_plural"] = knownPeopleDf_splitted["total_non_standard_plural"].apply(lambda x: sum_list(x))
print("done: total_non_standard_plural")
knownPeopleDf_splitted["count_apheresis"] = knownPeopleDf_splitted["count_apheresis"].apply(lambda x: sum_list(x))
print("done: count_apheresis")
knownPeopleDf_splitted["count_rhotacism"] = knownPeopleDf_splitted["count_rhotacism"].apply(lambda x: sum_list(x))
print("done: count_rhotacism")
knownPeopleDf_splitted["count_senhor_senhora"] = knownPeopleDf_splitted["count_senhor_senhora"].apply(lambda x: sum_list(x))
print("done: count_senhor_senhora")
knownPeopleDf_splitted["count_diminutive"] = knownPeopleDf_splitted["count_diminutive"].apply(lambda x: sum_list(x))
print("done: count_diminutive")
knownPeopleDf_splitted["count_foreign_words"] = knownPeopleDf_splitted["count_foreign_words"].apply(lambda x: sum_list(x))
print("done: count_foreign_words")
knownPeopleDf_splitted["count_prepositions"] = knownPeopleDf_splitted["count_prepositions"].apply(lambda x: sum_list(x))
print("done: count_prepositions")
knownPeopleDf_splitted["count_pronouns"] = knownPeopleDf_splitted["count_pronouns"].apply(lambda x: sum_list(x))
print("done: count_pronouns")
knownPeopleDf_splitted["count_interjections"] = knownPeopleDf_splitted["count_interjections"].apply(lambda x: sum_list(x))
print("done: count_interjections")
knownPeopleDf_splitted["count_mo_intensifier"] = knownPeopleDf_splitted["count_mo_intensifier"].apply(lambda x: sum_list(x))
print("done: mo_intensifier")

len(knownPeopleDf_splitted)

len(knownPeopleDf_splitted[knownPeopleDf_splitted['count_pronouns']<1])

# checking the number of unique speakers
repeatedSpeakers = []
onceSpeakers = []
idsCount = knownPeopleDf_splitted.unique_id_person.value_counts() # contains the counts of each unique ID in the knownPeopleDf_splitted

for unique_id, count in idsCount.iteritems():
# For each unique ID, the code checks if its corresponding count is greater than 1.
# If it is, the ID is added to the repeatedSpeakers list using the append() method.
# If the count is equal to 1, the ID is added to the onceSpeakers list using the append() method.
    if count > 1:
        repeatedSpeakers.append(unique_id)
    else:
        onceSpeakers.append(unique_id)

# counting number of speaker and related metrics
nUtterances = int(knownPeopleDf_splitted['total_utterance'].sum())
nWords = int(knownPeopleDf_splitted['total_words'].sum())
nUniqueSpeakers = len(idsCount)

if len(repeatedSpeakers) > 0:
# determine the number of speakers who appear multiple times in a dataset, either by directly counting the number of IDs that appear multiple
# times (if any), or by inferring the number of repeated IDs based on a specific characteristic
# of the "person_code" column (i.e., the presence of a comma).
    nRepeatSpeakers = len(repeatedSpeakers)
else: nRepeatSpeakers = len(knownPeopleDf_splitted[knownPeopleDf_splitted["person_code"].str.contains(",")])

utteranceBySpeakers = nUtterances/nUniqueSpeakers
utteranceBySpeakers = round(utteranceBySpeakers, 2) # rounding it up to only 2 decimal points

wordsBySpeakers = nWords/nUniqueSpeakers
wordsBySpeakers = round(wordsBySpeakers, 2) # rounding it up to only 2 decimal points

wordsByUtterance = nWords/nUtterances
wordsByUtterance = round(wordsByUtterance, 2) # rounding it up to only 2 decimal points

print(f"the total number of speakers is {nUniqueSpeakers} (known-unique speakers)")
print(f"the number of repeated speakers (they appear at least twice in the corpus) is {nRepeatSpeakers}")
print(f"the total number of utterances is {nUtterances}")
print(f"the total number of words is {nWords}\n\n=====\n")
print(f"the average number of utterance per speaker is {utteranceBySpeakers}")
print(f"the average number of words per speaker is {wordsBySpeakers}")
print(f"the average number of words per utterance is {wordsByUtterance}")

sexCount = knownPeopleDf_splitted.sex.value_counts()
schoolingCount = knownPeopleDf_splitted.schooling.value_counts()
ageCount = knownPeopleDf_splitted.age.value_counts()

print(f"the proportion of sexes is \n{sexCount}\n=======\n")
print(f"the proportion of schooling is \n{schoolingCount}\n=======\n")
print(f"the proportion of age is \n{ageCount}")

# group the dataframe by the 'grosexup' column and create separate dataframes for each group
groupedSex = knownPeopleDf_splitted.groupby('sex')
dataframesSex = [groupedSex.get_group(x) for x in groupedSex.groups]
# dataframesSex[0] = female people
# dataframesSex[1] = male people
# dataframesSex[2] = x people

# group the dataframe by the 'age' column and create separate dataframes for each group
groupedAge= knownPeopleDf_splitted.groupby('age')
dataframesAge = [groupedAge.get_group(x) for x in groupedAge.groups]
# dataframesAge[0] = A people
# dataframesAge[1] = B people
# dataframesAge[2] = C people
# dataframesAge[3] = D people
# dataframesAge[4] = M people
# dataframesAge[5] = x people

# group the dataframe by the 'schooling' column and create separate dataframes for each group
groupedSchooling= knownPeopleDf_splitted.groupby('schooling')
dataframesSchooling = [groupedSchooling.get_group(x) for x in groupedSchooling.groups]
# dataframesSchooling[0] = 1 people
# dataframesSchooling[1] = 2 people
# dataframesSchooling[2] = 3 people
# dataframesSchooling[3] = x people

# exporting the whole dataframe
knownPeopleDf_splitted.to_csv(textOutputPath+f"metadataWithTranscription_csv_{date}.csv")

# creating one dataframe for the sex variable (except the one with X)
sexDf = pd.concat(dataframesSex[:2])
sexDf.to_csv(textOutputPath+f"metadataWithTranscriptionSEX_csv_{date}.csv") # Export

# creating one dataframe for the age variable (except the one with X)
ageDf = pd.concat(dataframesAge[:5])
ageDf.to_csv(textOutputPath+f"metadataWithTranscriptionAGE_csv_{date}.csv") # Export

# creating one dataframe for the schooling variable (except the one with X)
schoolDf = pd.concat(dataframesSchooling[:3])
schoolDf.to_csv(textOutputPath+f"metadataWithTranscriptionSCHOOLING_csv_{date}.csv") # Export