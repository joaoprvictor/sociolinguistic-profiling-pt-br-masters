# -*- coding: utf-8 -*-
"""reading_header_files.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EH4o5LqIIPTfD8DCsJ2AHxb7Je5snAZH
"""

# importing libraries
import glob
import re
import pandas as pd
from datetime import datetime

headersPathList = glob.glob('C:\\Users\\joaop\\Desktop\\Corpora\\C-Oral-Brasil\\Appendix\\Metadata\\*.txt') # getting a list of the path of each file
print(headersPathList[135:139]) # checking
headersOutputPath = "C:\\Users\\joaop\\Desktop\\Corpora\\C-Oral-Brasil\\dissertation_codes\\text_output_files\\" # folder to save outputs

print(len(headersPathList)) # checking - it must be 139

# adapted from https://github.com/carlosjuniorcosta1/escritor_cabecalho_coral_esq_coral_brasil/blob/main/escritor_cabecalho.py
headersText = []
headersDfList = [] #list of DFs
for header_path in headersPathList: # reading the header files
    with open(header_path, 'r') as source: #important to use the 'r+' otherwise it won't read the files
        hds = source.read()
        headersText.append(hds) # appending the raw information
    #     #creating the dataframe with the header information
        headerDf = pd.DataFrame()
        # the steps below use regex to find the information after its "subtitle"
        headerDf['Title'] = [' '.join(re.findall(r'(?<=@Title:).+', hds))]
        headerDf['File'] = ' '.join(re.findall(r'(?<=@File:).+', hds))
        # old regex: [A-Z]{3},\s[a-zA-ZÀ-ÿũ]+\s\(.+?\)
        headerDf['Participants'] = ''.join(str(re.findall(r"[A-Z]{3},\s+[a-zA-ZÀ-ÿũ]+\s+\(.+?\)|[A-Z]{3},\s[a-zA-ZÀ-ÿũ]+\s+[a-zA-ZÀ-ÿũ]+\s+\(.+?\)", hds)))
        headerParticipants = '\n'.join(headerDf['Participants'].tolist())
        # # clean the information in the participants section
        headerParticipants = re.sub("\'',\s+|\[\(|,\s\''\)\]|'", '', headerParticipants)
        headerParticipants = re.sub(r'\\n', '\n', headerParticipants)
        headerParticipants = re.sub(r'\\t', '\t', headerParticipants)
        headerParticipants = re.sub(r'\'', '', headerParticipants)
        headerParticipants = re.sub('\'\[', '', headerParticipants)
        headerParticipants = re.sub('\(', '', headerParticipants)
        headerParticipants = re.sub('\)', '\n', headerParticipants)
        headerDf['Participants'] = headerParticipants #assign it to a column
        headerDf['Participants'] = headerDf['Participants'].apply(lambda x: re.sub(r'\)\](?=$)', '', x)) #cleaning
        # # the steps below use regex to find the information after its "subtitle"
        headerDf['Date'] = ' '.join(re.findall(r'(?<=@Date:).+', hds))
        headerDf['Place'] = ' '.join(re.findall(r'(?<=@Place:).+', hds))
        headerDf['Situation'] = ' '.join(re.findall(r'(?<=@Situation:).+', hds))
        headerDf['Topic'] = ' '.join(re.findall(r'(?<=@Topic:).+', hds))
        headerDf['Source'] = ' '.join(re.findall(r'(?<=@Source:).+', hds))
        headerDf['Class'] = ' '.join(re.findall(r'(?<=@Class:).+', hds))
        headerDf['Length'] = ' '.join(re.findall(r'(?<=@Length:).+', hds))
        headerDf['Transcriber'] = ' '.join(re.findall(r'(?<=@Transcriber:).+', hds))
        headerDf['Revisor'] = ' '.join(re.findall(r'(?<=@Revisor:).+', hds))
        headersDfList.append(headerDf) # append each dataframe into a list of DFs

headersDf = pd.concat(headersDfList) # concatenating all header dataframes into one
print(f"size BEFORE exploding Participants: {len(headersDf)}")
headersDf.Participants = headersDf.Participants.apply(lambda x: re.sub(r"\[\]\]","", x)) # deleting []]
headersDf.Participants = headersDf.Participants.str.split("\n") #splitting the "Participants" column into a list of string (a participant per string)

headersDf = headersDf.explode("Participants") #taking the speaker info out of a list in order to edit it
print(f"size AFTER exploding Participants: {len(headersDf)}")

repr(headersDf.iloc[0,1])

headersDf.Participants = headersDf.Participants.str.replace("^, ", "") # delete comma followed by space at the beginning of a cell
headersDf.Participants = headersDf.Participants.str.replace(" $", "") # delete comma followed by space at the beginning of a cell
headersDf = headersDf[headersDf.Participants != "]"] # deleting ]
headersDf = headersDf[headersDf.Participants != "\'\]\'"] # deleting ']'
headersDf.Participants = headersDf.Participants.str.replace("\", \"", "") # deleting ", "
headersDf.Participants = headersDf.Participants.str.replace("\"", "") # deleting "
headersDf.Participants = headersDf.Participants.str.replace("\", ", "")# deleting ",\s
headersDf.Participants = headersDf.Participants.str.replace("[", "") # deleting [
headersDf.Participants = headersDf.Participants.str.replace("]", "") # deleting ]
headersDf.Participants = headersDf.Participants.str.replace("\\\'\"\\\'", "") # deleting \'"\'
headersDf.Participants = headersDf.Participants.str.replace(", ", ",") #replacing ,\s by , only
headersDf.Participants = headersDf.Participants.str.replace("^,", "") #replacing , at the beginning by nothing
headersDf = headersDf[headersDf.Participants != "\'\'"] # unselecting rows in which the participants column is ''
headersDf = headersDf[headersDf.Participants != ""] # unselecting rows in which the participants column is empty
headersDf = headersDf[headersDf.Participants != " "] # unselecting rows in which the participants column is a whitespace
headersDf['File'] = headersDf['File'].str.replace("\s+", "") #replacing white spaces by nothing in the File column

print(f"size: {len(headersDf)}")

repr(headersDf.iloc[5,3])

# the split function gets the comma as a divider and returns a list of strings
# whose each item is a speaker's piece of information
#example: TER[0],Terezinha female[1],C[2],1[3],homemaker[4],participant[5],Belo Horizonte/MG[6]
headersDf['acronym'] = headersDf['Participants'].str.split(",", expand = True)[0] #speaker code
headersDf['acronym'] = headersDf['acronym'].str.replace("\"","")
headersDf['first_name_sex'] = headersDf['Participants'].str.split(",", expand = True)[1]
headersDf['age'] = headersDf['Participants'].str.split(",", expand = True)[2]
headersDf['schooling'] = headersDf['Participants'].str.split(",", expand = True)[3]
headersDf['job'] = headersDf['Participants'].str.split(",", expand = True)[4]
headersDf['role'] = headersDf['Participants'].str.split(",", expand = True)[5]
headersDf['origin'] = headersDf['Participants'].str.split(",", expand = True)[6]
#some speakers have extra information (if they had been born in another city, for example)
# the speakers who don't have that will receive a "no_extra_info"
headersDf['extra_information'] = headersDf['Participants'].str.split(",", expand = True)[7]
headersDf['extra_information'] = headersDf['extra_information'].fillna("no_extra_info")


# 1st name and sex were stored in the same item, so now we're dividing this item into two parts
headersDf['first_name'] = headersDf['first_name_sex'].str.split(" ", expand = True)[0]
headersDf['first_name'] = headersDf['first_name'].str.replace("\s+", "") #replacing extra spaces by nothing
headersDf['sex'] = headersDf['first_name_sex'].str.split(" ", expand = True)[1]
headersDf['sex'] = headersDf['sex'].str.replace("\s+", "")#replacing extra spaces by nothing
headersDf = headersDf[headersDf['first_name_sex'].notnull()] #selecting the fulfilled rows in first_name_sex
headersDf = headersDf[headersDf['first_name_sex'] != ""] #unselecting the empty rows in first_name_sex (just to be sure)

headersDf = headersDf.reset_index() #put index into the DF

#create columns with the register, context and interacction type by dividing the Class column with a comma as a divider
headersDf['register'] = headersDf['Class'].str.split(', ', -1, expand=True)[0]
headersDf['context'] = headersDf['Class'].str.split(',', -1, expand=True)[1]
headersDf['interaction'] = headersDf['Class'].str.split(',', expand=True)[2]
headersDf.columns = headersDf.columns.str.lower() #putting all column names in lower case

#assigning a person ID in the file and unique ID
headersDf['person_code'] = headersDf['file'] + headersDf['acronym']
headersDf['person_code'] = headersDf['person_code'].str.replace("\s+", "")

#creating an unique ID for each speaker, combining the person code + DF index
headersDf['unique_id_person'] = headersDf['file'] + headersDf['acronym'] + headersDf.index.astype(str)
headersDf['unique_id_person'] = headersDf['unique_id_person'].str.replace("\s+", "")

headersDf[:5]

#checking
print(headersDf.columns)

def deleteExtraWhiteSpaces(dataframe):
    for column in dataframe:
        dataframe[column] = dataframe[column].astype(str) # converting the dataframe column types to string
        dataframe[column] = dataframe[column].str.strip() #  and deleting extra white spaces
    return dataframe

headersFinalDf = deleteExtraWhiteSpaces(headersDf) #implementing the function

# reordering/selecting the columns
headersFinalDf = headersDf[['file', 'acronym', 'person_code', 'unique_id_person', 'first_name',
                                'sex', 'age', 'schooling', 'origin', 'job', 'extra_information', 'interaction','role',
                                'register', 'context', 'title', 'date', 'situation', 'topic',
                                 'place', 'source', 'class', 'length', 'transcriber', 'revisor']]

headersFinalDf.columns

#combining personal info about the speakers so that we can retrieve repeated speakers
headersFinalDf['combined_person_info'] = headersFinalDf[headersFinalDf.columns[4:11]].apply(lambda x: '_'.join(x.str.replace("\s", "").astype(str)),axis=1)

# filter dataframe
unknownPeopleDf = headersFinalDf.loc[(headersFinalDf['sex'].str.contains(r"x|female|male")) &
                        (headersFinalDf['age'].str.contains("x")) &
                        (headersFinalDf['schooling'].str.contains("x"))]

knownPeopleDf = headersFinalDf.loc[(headersFinalDf['sex'].str.contains(r"female|male")) &
                        (headersFinalDf['age'].str.contains("x")==False) &
                        (headersFinalDf['schooling'].str.contains("x")==False)]

# getting duplicates
headersFinalDuplicatesDf = knownPeopleDf[knownPeopleDf.combined_person_info.duplicated(keep=False)]
dfPersonDupli = headersFinalDuplicatesDf.groupby("combined_person_info", as_index=False).count() #['unique_id_person'].sum()

# #putting duplicated values in a list
personDupliList = dfPersonDupli["combined_person_info"].to_list()
len(personDupliList)

def replaceInfo(combinedInfo, dfPersonInfo): # deleting different IDs for the same person and assigning only one ID
    finalUniqueId = ""
    for index, row in dfPersonInfo.iterrows():
        if row["combined_person_info"] == combinedInfo:
            finalUniqueId = row["unique_id_person"]
            break
    return finalUniqueId

# ======
def replaceName(uniqueId, df, combinedInfo): #replace ID in the dataframe for the duplicates
    df.loc[df.combined_person_info == combinedInfo, 'unique_id_person'] = uniqueId

for item in personDupliList: # applying functions into the dataframe
    uniqueId = replaceInfo(item, knownPeopleDf)
    replaceName(uniqueId, knownPeopleDf, item)

allPeopleInfoDf = pd.concat([knownPeopleDf, unknownPeopleDf])

len(allPeopleInfoDf)

# exporting
date = datetime.now().strftime('%Y-%m-%d')
allPeopleInfoDf.to_csv(headersOutputPath+f'allPeopleInfoDf_csv_{date}.csv')
allPeopleInfoDf.to_excel(headersOutputPath+f'allPeopleInfoDf_excel_{date}.xlsx')

allPeopleInfoDf[allPeopleInfoDf.person_code == 'bfamcv22PRI']